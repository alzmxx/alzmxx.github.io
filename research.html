<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="people.html">People</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<h2>Overview</h2>
<p>My research focuses on control, optimization, and machine learning for decision-making in societal systems, with applications in robotics, autonomy, transportation, logistics, and finance. This research is supported by the National Natural Science Foundation of China and the Fundamental Research Funds for the Central Universities. I gratefully acknowledge these supports and collaborations.
</p>
<h2>Research Directions</h2>
<h3>Reinforcement Learning</h3>
<p>This line of research explores the theoretical and algorithmic foundations of offline and safe multi-agent reinforcement learning (MARL). 
The objective is to enable reliable policy learning from static datasets and to provide formal guarantees on safety, robustness, and performance. 
By incorporating Bayesian inference, uncertainty quantification, and posterior information analysis, this work establishes principled connections between reinforcement learning, optimization, and statistical decision theory.
</p>
<h3>World Foundation Models</h3>
<p>This direction investigates the integration of world models and reinforcement learning (RL) for scalable and robust decision-making under uncertainty. 
World models—trained on multimodal and interactive data—simulate latent dynamics of agents, environments, and infrastructure, allowing intelligent systems to plan and adapt safely across diverse conditions. 
By combining generative modeling, model-based planning, and policy optimization, this research aims to develop foundation-level decision models that generalize across domains and tasks.
</p>
<h3>Bandit Algorithms</h3>
<p>This research area focuses on adaptive decision-making under uncertainty, particularly within the frameworks of contextual bandits, online learning, and streaming data. 
It seeks to design algorithms that balance exploration and exploitation efficiently in dynamic environments, supported by rigorous non-asymptotic and regret analyses. 
These methods provide theoretical insights and practical tools for high-dimensional reinforcement learning and sequential decision problems.
</p>
<h3>Dynamic Programming</h3>
<p>This direction advances the analytical foundations of dynamic programming, optimal control, and network optimization for multi-agent and large-scale systems. 
It studies the structural properties, stability, and coordination of decision processes across temporal and spatial scales, with applications to intelligent transportation networks, distributed control, and autonomous system optimization.
</p>
</td>
</tr>
</table>
</body>
</html>
